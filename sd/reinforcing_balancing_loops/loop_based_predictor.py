# ç³»ç»ŸåŠ¨åŠ›å­¦å¢å¼º-è°ƒèŠ‚å›è·¯æ¨¡å‹ï¼šè¯­ä¹‰æ¼”åŒ–é¢„æµ‹
# åŸºäºç»å…¸ç³»ç»ŸåŠ¨åŠ›å­¦ç†è®ºï¼šå¢å¼ºå›è·¯ + è°ƒèŠ‚å›è·¯ + æ—¶æ»åé¦ˆ
# ä¸¥æ ¼éµå¾ªå›è·¯å› æœå…³ç³»å’Œåé¦ˆæœºåˆ¶

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import json
from scipy.optimize import minimize

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.family'] = 'sans-serif'

# å°è¯•è®¾ç½®ä¸­æ–‡å­—ä½“
try:
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
except:
    pass

# å¼ºåˆ¶ä½¿ç”¨æ”¯æŒä¸­æ–‡çš„å­—ä½“
import matplotlib.font_manager as fm
try:
    # æŸ¥æ‰¾ç³»ç»Ÿä¸­æ–‡å­—ä½“
    font_path = None
    for font in fm.findSystemFonts():
        if 'simhei' in font.lower() or 'microsoft yahei' in font.lower():
            font_path = font
            break

    if font_path:
        font_prop = fm.FontProperties(fname=font_path)
        plt.rcParams['font.sans-serif'] = [font_prop.get_name()]
    else:
        # å¦‚æœæ‰¾ä¸åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS']
except:
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS']

# ====================== ç³»ç»ŸåŠ¨åŠ›å­¦å›è·¯ç†è®ºåŸºç¡€ ======================
"""
ç³»ç»ŸåŠ¨åŠ›å­¦å¢å¼º-è°ƒèŠ‚å›è·¯æ¨¡å‹

æ ¸å¿ƒå›è·¯ç»“æ„ï¼š

1. å¢å¼ºå›è·¯ï¼ˆReinforcing Loop R1ï¼‰ï¼š
   è¯­ä¹‰èšåˆé€Ÿç‡ â†’[+] æ›²ç‡ â†’[+] ä¸‹ä¸€å±‚èšåˆé€Ÿç‡
   (å‰å±‚èšåˆé©±åŠ¨åå±‚èšåˆï¼Œå½¢æˆæ­£åé¦ˆ)

2. è°ƒèŠ‚å›è·¯ï¼ˆBalancing Loop B1ï¼‰ï¼š
   æ›²ç‡ â†’[+] è¯­ä¹‰ç¨³å®šæ€§ â†’[-] èšåˆé€Ÿç‡
   (èšåˆè¿‡åº¦æ—¶é€šè¿‡ç¨³å®šæ€§æœºåˆ¶æŠ‘åˆ¶)

3. è°ƒèŠ‚å›è·¯ï¼ˆBalancing Loop B2ï¼‰ï¼š
   æ›²ç‡ â†’[+] è·ç¦»å˜åŒ– â†’[+] èšåˆé˜»åŠ› â†’[-] èšåˆé€Ÿç‡
   (èšåˆè¿‡åº¦æ—¶é€šè¿‡è·ç¦»å˜åŒ–å¢åŠ é˜»åŠ›)

4. æ—¶æ»åé¦ˆå›è·¯ï¼ˆDelayed Feedbackï¼‰ï¼š
   å½“å‰èšåˆ â†’[æ—¶æ»] å½±å“æœªæ¥èšåˆ

æ•°å­¦è¡¨è¾¾ï¼š
æ›²ç‡æ¼”åŒ–é€Ÿç‡(L) = R1_gain Ã— æ›²ç‡æ¼”åŒ–é€Ÿç‡(L-1) Ã— (1 - B1_effect - B2_effect)

å…¶ä¸­ï¼š
- R1_gain: å¢å¼ºå›è·¯å¢ç›Šï¼ˆæ­£åé¦ˆå¼ºåº¦ï¼‰
- B1_effect: è°ƒèŠ‚å›è·¯B1æ•ˆæœï¼ˆè¯­ä¹‰ç¨³å®šæ€§æŠ‘åˆ¶ï¼‰
- B2_effect: è°ƒèŠ‚å›è·¯B2æ•ˆæœï¼ˆè·ç¦»å˜åŒ–æŠ‘åˆ¶ï¼‰
"""

# ====================== å›è·¯å‚æ•°è®¾ç½® ======================
# å¢å¼ºå›è·¯å‚æ•°
R1_GAIN = 0.6          # å¢å¼ºå›è·¯å¢ç›Š (0.4-0.8)

# è°ƒèŠ‚å›è·¯B1å‚æ•°ï¼ˆè¯­ä¹‰ç¨³å®šæ€§ï¼‰
B1_SEMANTIC_GAIN = 0.3 # è¯­ä¹‰ç¨³å®šæ€§å¢ç›Š
B1_SEMANTIC_DELAY = 1  # è¯­ä¹‰åé¦ˆå»¶è¿Ÿ

# è°ƒèŠ‚å›è·¯B2å‚æ•°ï¼ˆè·ç¦»å˜åŒ–ï¼‰
B2_DISTANCE_GAIN = 0.2 # è·ç¦»å˜åŒ–å¢ç›Š
B2_DISTANCE_THRESHOLD = 0.001  # è·ç¦»å˜åŒ–é˜ˆå€¼

# æ—¶æ»å‚æ•°
FEEDBACK_DELAY = 1     # æ•´ä½“åé¦ˆå»¶è¿Ÿå±‚æ•°

# ====================== å›è·¯çŠ¶æ€å˜é‡ ======================
class LoopState:
    """ç³»ç»ŸåŠ¨åŠ›å­¦å›è·¯çŠ¶æ€"""
    def __init__(self):
        self.semantic_stability = 0.0  # è¯­ä¹‰ç¨³å®šæ€§çŠ¶æ€
        self.distance_resistance = 0.0 # è·ç¦»é˜»åŠ›çŠ¶æ€
        self.aggregation_momentum = 0.0 # èšåˆåŠ¨é‡

# ====================== å¢å¼ºå›è·¯è®¡ç®—å‡½æ•° ======================
def reinforcing_loop_effect(prev_dKdt, current_state, r1_gain=R1_GAIN):
    """
    è®¡ç®—å¢å¼ºå›è·¯æ•ˆæœï¼šå‰å±‚èšåˆé©±åŠ¨å½“å‰å±‚èšåˆ

    å‚æ•°ï¼š
    prev_dKdt: å‰å±‚èšåˆé€Ÿç‡
    current_state: å½“å‰å›è·¯çŠ¶æ€
    r1_gain: å¢å¼ºå›è·¯å¢ç›Š

    è¿”å›ï¼š
    å¢å¼ºå›è·¯è´¡çŒ®å€¼
    """
    # å¢å¼ºå›è·¯ï¼šå‰å±‚èšåˆæ­£å‘æ¨åŠ¨å½“å‰å±‚èšåˆ
    reinforcing_effect = r1_gain * prev_dKdt

    # åŠ å…¥åŠ¨é‡æ•ˆåº”ï¼ˆå¢å¼ºå›è·¯ç§¯ç´¯ï¼‰
    current_state.aggregation_momentum = 0.8 * current_state.aggregation_momentum + 0.2 * reinforcing_effect

    return current_state.aggregation_momentum

# ====================== è°ƒèŠ‚å›è·¯B1è®¡ç®—å‡½æ•° ======================
def balancing_loop_b1_effect(current_K, current_S, current_state=None,
                           b1_gain=B1_SEMANTIC_GAIN, b1_delay=B1_SEMANTIC_DELAY):
    """
    è®¡ç®—è°ƒèŠ‚å›è·¯B1æ•ˆæœï¼šè¯­ä¹‰ç¨³å®šæ€§æŠ‘åˆ¶è¿‡åº¦èšåˆ

    å‚æ•°ï¼š
    current_K: å½“å‰æ›²ç‡ï¼ˆå®é™…è§‚æµ‹å€¼ï¼‰
    current_S: å½“å‰è¯­ä¹‰æ¼‚ç§»ç³»æ•°ï¼ˆå®é™…è§‚æµ‹å€¼ï¼‰
    current_state: å½“å‰å›è·¯çŠ¶æ€ï¼ˆå¯é€‰ï¼Œç”¨äºå…¼å®¹æ€§ï¼‰

    è¿”å›ï¼š
    è°ƒèŠ‚å›è·¯B1æŠ‘åˆ¶æ•ˆæœï¼ˆå®Œå…¨åŸºäºå®é™…è§‚æµ‹å€¼ï¼‰
    """
    # è¯­ä¹‰ç¨³å®šæ€§ = 1 / (1 + è¯­ä¹‰æ¼‚ç§»Â²) - ç›´æ¥åŸºäºå½“å‰å®é™…è§‚æµ‹å€¼
    semantic_stability = 1.0 / (1.0 + current_S ** 2)

    # è°ƒèŠ‚å›è·¯ï¼šæ ¹æ®èšåˆæ–¹å‘å†³å®šæŠ‘åˆ¶å¼ºåº¦
    # å¦‚æœKä¸ºæ­£ï¼ˆèšåˆï¼‰ï¼Œç¨³å®šæ€§æŠ‘åˆ¶èšåˆï¼›å¦‚æœKä¸ºè´Ÿï¼ˆç¦»æ•£ï¼‰ï¼Œç¨³å®šæ€§æŠ‘åˆ¶ç¦»æ•£
    if current_K >= 0:
        # æ­£èšåˆæ—¶ï¼Œç¨³å®šæ€§æŠ‘åˆ¶è¿‡åº¦èšåˆ
        stability_suppression = b1_gain * semantic_stability * current_K
    else:
        # è´Ÿèšåˆæ—¶ï¼Œç¨³å®šæ€§æŠ‘åˆ¶è¿‡åº¦ç¦»æ•£ï¼ˆäº§ç”Ÿæ­£å‘è°ƒèŠ‚ï¼‰
        stability_suppression = -b1_gain * semantic_stability * abs(current_K)

    return stability_suppression

# ====================== è°ƒèŠ‚å›è·¯B2è®¡ç®—å‡½æ•° ======================
def balancing_loop_b2_effect(current_D, prev_D, current_state=None, current_K=None,
                           b2_gain=B2_DISTANCE_GAIN, b2_threshold=B2_DISTANCE_THRESHOLD):
    """
    è®¡ç®—è°ƒèŠ‚å›è·¯B2æ•ˆæœï¼šè·ç¦»å˜åŒ–å¢åŠ èšåˆé˜»åŠ›

    å‚æ•°ï¼š
    current_D: å½“å‰è·ç¦»ï¼ˆå®é™…è§‚æµ‹å€¼ï¼‰
    prev_D: å‰å±‚è·ç¦»ï¼ˆå®é™…è§‚æµ‹å€¼ï¼‰
    current_state: å½“å‰å›è·¯çŠ¶æ€ï¼ˆå¯é€‰ï¼Œç”¨äºå…¼å®¹æ€§ï¼‰
    current_K: å½“å‰æ›²ç‡ï¼ˆå®é™…è§‚æµ‹å€¼ï¼Œç”¨äºåˆ¤æ–­è¶‹åŠ¿æ–¹å‘ï¼‰

    è¿”å›ï¼š
    è°ƒèŠ‚å›è·¯B2æŠ‘åˆ¶æ•ˆæœï¼ˆå®Œå…¨åŸºäºå®é™…è§‚æµ‹å€¼ï¼‰
    """
    # è·ç¦»å˜åŒ–å¹…åº¦å’Œæ–¹å‘ - ç›´æ¥åŸºäºå®é™…è§‚æµ‹å€¼
    distance_change = current_D - prev_D  # ä¿æŒç¬¦å·

    # è·ç¦»é˜»åŠ›ï¼šæ ¹æ®èšåˆæ–¹å‘å†³å®šé˜»åŠ›
    if abs(distance_change) > b2_threshold:
        # åŸºç¡€é˜»åŠ›
        base_resistance = b2_gain * (abs(distance_change) / b2_threshold)

        # æ ¹æ®èšåˆæ–¹å‘è°ƒæ•´é˜»åŠ›æ–¹å‘
        if current_K is not None:
            if current_K >= 0:
                # æ­£èšåˆæ—¶ï¼Œè·ç¦»å¢åŠ äº§ç”Ÿé˜»åŠ›ï¼Œè·ç¦»å‡å°‘å‡å°‘é˜»åŠ›
                distance_resistance = base_resistance * (distance_change / abs(distance_change)) if distance_change != 0 else 0
            else:
                # è´Ÿèšåˆæ—¶ï¼Œè·ç¦»å¢åŠ å¯èƒ½ä¸æ˜¯é˜»åŠ›ï¼ˆç¦»æ•£è¶‹åŠ¿ï¼‰ï¼Œæ‰€ä»¥å‡å°é˜»åŠ›
                distance_resistance = base_resistance * 0.5 * (distance_change / abs(distance_change)) if distance_change != 0 else 0
        else:
            # å¦‚æœæ²¡æœ‰Kä¿¡æ¯ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•ï¼ˆæ€»æ˜¯æ­£é˜»åŠ›ï¼‰
            distance_resistance = base_resistance
    else:
        distance_resistance = 0.0

    return distance_resistance

# ====================== ä¸»é¢„æµ‹å‡½æ•° ======================
def loop_based_predict(token_data, start_layer=12, end_layer=16):
    """
    åŸºäºå¢å¼º-è°ƒèŠ‚å›è·¯ç»„åˆçš„ç³»ç»ŸåŠ¨åŠ›å­¦é¢„æµ‹

    å‚æ•°ï¼š
    token_data: å•ä¸ªtokençš„å±‚æ•°æ®
    start_layer: é¢„æµ‹å¼€å§‹å±‚
    end_layer: é¢„æµ‹ç»“æŸå±‚

    è¿”å›ï¼š
    é¢„æµ‹ç»“æœå­—å…¸
    """
    # æå–æ•°æ®
    layers = token_data['å±‚'].values
    K_actual = token_data['æ›²ç‡ K(t)'].values
    D_actual = token_data['å¹³å‡æ¬§æ°è·ç¦» D(t)'].values
    S_actual = token_data['è¯­ä¹‰æ¼‚ç§»ç³»æ•° S(t)'].values
    dKdt_actual = token_data['æ›²ç‡æ¼”åŒ–é€Ÿç‡'].values

    # åˆå§‹åŒ–å›è·¯çŠ¶æ€
    loop_state = LoopState()

    # åˆå§‹åŒ–é¢„æµ‹æ•°ç»„
    predicted_K = []
    predicted_dKdt = []

    # æ ¹æ®start_layerè®¡ç®—åˆå§‹åŒ–å±‚ï¼ˆé¢„æµ‹start_layeréœ€è¦start_layer-1å±‚çš„æ•°æ®ï¼‰
    init_layer = start_layer - 1
    init_layer_idx = np.where(layers == init_layer)[0]
    if len(init_layer_idx) == 0:
        return None

    idx_init = init_layer_idx[0]
    current_K = K_actual[idx_init]  # ä»åˆå§‹åŒ–å±‚çš„å®é™…Kå¼€å§‹
    current_D = D_actual[idx_init]
    current_S = S_actual[idx_init]

    # è®¡ç®—åˆå§‹å‰å±‚èšåˆé€Ÿç‡
    prev_dKdt = dKdt_actual[idx_init]  # åˆå§‹åŒ–å±‚çš„å®é™…æ›²ç‡æ¼”åŒ–é€Ÿç‡

    # é¢„æµ‹æ¯ä¸€å±‚
    for layer in range(start_layer, end_layer + 1):
        # è·å–å‰ä¸€å±‚å®é™…è§‚æµ‹æ•°æ®
        prev_layer = layer - 1
        prev_idx = np.where(layers == prev_layer)[0]
        print(f"é¢„æµ‹å±‚: {layer}, å‰å±‚: {prev_layer}, prev_idx: {prev_idx}, å½“å‰K: {current_K}, å½“å‰D: {current_D}, å½“å‰S: {current_S}")
        if len(prev_idx) > 0:
            # ä½¿ç”¨å‰ä¸€å±‚çš„å®é™…è§‚æµ‹æ•°æ®
            current_K = K_actual[prev_idx[0]]  # é¢„æµ‹èµ·ç‚¹æ˜¯å‰ä¸€å±‚çš„å®é™…K
            S_prev = S_actual[prev_idx[0]]
            D_prev = D_actual[prev_idx[0]]
            prev_dKdt = dKdt_actual[prev_idx[0]]  # å‰ä¸€å±‚çš„å®é™…æ›²ç‡æ¼”åŒ–é€Ÿç‡
            print(f"  ç”¨å‰å±‚å®é™…è§‚æµ‹å€¼: K_prev={current_K}, S_prev={S_prev}, D_prev={D_prev}, prev_dKdt={prev_dKdt}")
        else:
            # å¦‚æœå‰ä¸€å±‚æ²¡æœ‰å®é™…æ•°æ®ï¼Œä½¿ç”¨é¢„æµ‹æ•°æ®ï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰
            S_prev = current_S
            D_prev = current_D
            print(f"  ç”¨é¢„æµ‹å€¼ S_prev={S_prev}, D_prev={D_prev}")

        # è®¡ç®—å„ä¸ªå›è·¯çš„æ•ˆæœ - å®Œå…¨åŸºäºå®é™…è§‚æµ‹å€¼
        r1_effect = reinforcing_loop_effect(prev_dKdt, loop_state)
        b1_effect = balancing_loop_b1_effect(current_K, S_prev)
        
        # è·å–å‰å‰å±‚è·ç¦»ç”¨äºB2å›è·¯
        prev_prev_layer = layer - 2
        prev_prev_idx = np.where(layers == prev_prev_layer)[0]
        prev_prev_D = D_actual[prev_prev_idx[0]] if len(prev_prev_idx) > 0 else D_prev
        
        b2_effect = balancing_loop_b2_effect(D_prev, prev_prev_D, current_K=current_K)

        # ç»¼åˆå›è·¯æ•ˆæœï¼šåŸºç¡€è¶‹åŠ¿ + è°ƒèŠ‚ä¿®æ­£
        # åŸºç¡€è¶‹åŠ¿ï¼šä¿æŒå‰ä¸€å±‚å˜åŒ–è¶‹åŠ¿
        base_trend = prev_dKdt
        # è°ƒèŠ‚ä¿®æ­£ï¼šå›è·¯æ•ˆæœæä¾›å¾®è°ƒ
        regulation_factor = 1.0 + r1_effect * 0.1 - b1_effect * 0.1 - b2_effect * 0.1
        
        net_flow_rate = base_trend * regulation_factor

        # é¢„æµ‹å½“å‰å±‚æ›²ç‡
        predicted_K_val = current_K + net_flow_rate
        predicted_dKdt_val = net_flow_rate

        # å­˜å‚¨é¢„æµ‹ç»“æœ
        predicted_K.append(predicted_K_val)
        predicted_dKdt.append(predicted_dKdt_val)

        # æ›´æ–°å½“å‰çŠ¶æ€ä¸ºé¢„æµ‹å€¼ï¼ˆç”¨äºä¸‹ä¸€è½®é¢„æµ‹ï¼Œå¦‚æœéœ€è¦çš„è¯ï¼‰
        current_K = predicted_K_val
        current_D = D_prev if len(prev_idx) > 0 else current_D
        current_S = S_prev if len(prev_idx) > 0 else current_S

    return {
        'layers': list(range(start_layer, end_layer + 1)),
        'predicted_K': predicted_K,
        'predicted_dKdt': predicted_dKdt,
        'loop_states': {
            'semantic_stability': loop_state.semantic_stability,
            'distance_resistance': loop_state.distance_resistance,
            'aggregation_momentum': loop_state.aggregation_momentum
        }
    }

# ====================== å›è·¯åˆ†æå‡½æ•° ======================
def analyze_loop_dynamics(token_data, prediction_result):
    """
    åˆ†æå›è·¯åŠ¨æ€è¡Œä¸º
    """
    layers = prediction_result['layers']
    loop_states = prediction_result['loop_states']

    print("å›è·¯åŠ¨æ€åˆ†æ:")
    print(f"  æœ€ç»ˆè¯­ä¹‰ç¨³å®šæ€§: {loop_states['semantic_stability']:.4f}")
    print(f"  æœ€ç»ˆè·ç¦»é˜»åŠ›: {loop_states['distance_resistance']:.4f}")
    print(f"  æœ€ç»ˆèšåˆåŠ¨é‡: {loop_states['aggregation_momentum']:.4f}")

    # åˆ†æä¸»å¯¼å›è·¯
    if abs(loop_states['aggregation_momentum']) > abs(loop_states['semantic_stability'] + loop_states['distance_resistance']):
        print("  ä¸»å¯¼å›è·¯: å¢å¼ºå›è·¯ (æ­£åé¦ˆä¸»å¯¼)")
    else:
        print("  ä¸»å¯¼å›è·¯: è°ƒèŠ‚å›è·¯ (è´Ÿåé¦ˆä¸»å¯¼)")

# ====================== å¯è§†åŒ–å‡½æ•° ======================
def plot_loop_comparison(actual_data, predicted_data, token_name, save_path):
    """
    ç”Ÿæˆå›è·¯æ¨¡å‹é¢„æµ‹vså®é™…å¯¹æ¯”å›¾
    """
    layers = predicted_data['layers']
    pred_K = predicted_data['predicted_K']
    pred_dKdt = predicted_data['predicted_dKdt']

    # æå–å®é™…æ•°æ®
    actual_K = []
    actual_dKdt = []
    for layer in layers:
        actual_row = actual_data[actual_data['å±‚'] == layer]
        if len(actual_row) > 0:
            actual_K.append(actual_row['æ›²ç‡ K(t)'].values[0])
            actual_dKdt.append(actual_row['æ›²ç‡æ¼”åŒ–é€Ÿç‡'].values[0])
        else:
            actual_K.append(np.nan)
            actual_dKdt.append(np.nan)

    # åˆ›å»ºå›¾è¡¨
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

    # æ›²ç‡å¯¹æ¯”
    ax1.plot(layers, actual_K, 'b-o', label='å®é™…æ›²ç‡ K(t)', linewidth=2, markersize=6)
    ax1.plot(layers, pred_K, 'r--s', label='é¢„æµ‹æ›²ç‡ K(t)', linewidth=2, markersize=6)
    ax1.set_title(f'ç³»ç»ŸåŠ¨åŠ›å­¦å¢å¼º-è°ƒèŠ‚å›è·¯æ¨¡å‹ï¼š{token_name}è¯­ä¹‰æ¼”åŒ–é¢„æµ‹', fontsize=14, fontweight='bold')
    ax1.set_xlabel('å±‚æ•°', fontsize=12)
    ax1.set_ylabel('æ›²ç‡ K(t)', fontsize=12)
    ax1.legend(fontsize=10)
    ax1.grid(True, alpha=0.3)

    # æ·»åŠ å›è·¯è¯´æ˜
    ax1.text(0.02, 0.98, 'R1: å¢å¼ºå›è·¯\nB1: è¯­ä¹‰ç¨³å®šæ€§è°ƒèŠ‚\nB2: è·ç¦»å˜åŒ–è°ƒèŠ‚',
             transform=ax1.transAxes, fontsize=8, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

    # æ›²ç‡å˜åŒ–ç‡å¯¹æ¯”
    ax2.plot(layers, actual_dKdt, 'b-o', label='å®é™…æ›²ç‡æ¼”åŒ–é€Ÿç‡', linewidth=2, markersize=6)
    ax2.plot(layers, pred_dKdt, 'r--s', label='é¢„æµ‹æ›²ç‡æ¼”åŒ–é€Ÿç‡', linewidth=2, markersize=6)
    ax2.set_xlabel('å±‚æ•°', fontsize=12)
    ax2.set_ylabel('æ›²ç‡æ¼”åŒ–é€Ÿç‡', fontsize=12)
    ax2.legend(fontsize=10)
    ax2.grid(True, alpha=0.3)

    print(f"å›è·¯æ¨¡å‹å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}")

def plot_all_tokens_comparison(all_results, save_path):
    """
    ç”Ÿæˆæ‰€æœ‰tokençš„ç»¼åˆå¯¹æ¯”å›¾ - ç°ä»£åŒ–ç¾åŒ–ç‰ˆæœ¬
    """
    n_tokens = len(all_results)
    if n_tokens == 0:
        return

    # ä¸º6ä¸ªtokenè®¾è®¡2x3å¸ƒå±€
    if n_tokens == 6:
        rows, cols = 2, 3
    else:
        cols = int(np.ceil(np.sqrt(n_tokens)))
        rows = int(np.ceil(n_tokens / cols))

    # è®¡ç®—å…¨å±€Yè½´èŒƒå›´ï¼ˆåŸºäºå®é™…è§‚æµ‹å€¼ï¼‰
    global_k_min, global_k_max = float('inf'), float('-inf')
    global_dkdt_min, global_dkdt_max = float('inf'), float('-inf')
    
    for result in all_results:
        actual_data = result['actual_data']
        prediction = result['prediction']
        layers = prediction['layers']
        
        # æ”¶é›†è¯¥tokençš„å®é™…æ•°æ®
        actual_K = []
        actual_dKdt = []
        for layer in layers:
            actual_row = actual_data[actual_data['å±‚'] == layer]
            if len(actual_row) > 0:
                actual_K.append(actual_row['æ›²ç‡ K(t)'].values[0])
                actual_dKdt.append(actual_row['æ›²ç‡æ¼”åŒ–é€Ÿç‡'].values[0])
        
        if actual_K:
            global_k_min = min(global_k_min, min(actual_K))
            global_k_max = max(global_k_max, max(actual_K))
        if actual_dKdt:
            global_dkdt_min = min(global_dkdt_min, min(actual_dKdt))
            global_dkdt_max = max(global_dkdt_max, max(actual_dKdt))
    
    # ä¸ºYè½´æ·»åŠ ä¸€äº›è¾¹è·
    k_margin = (global_k_max - global_k_min) * 0.1
    dkdt_margin = (global_dkdt_max - global_dkdt_min) * 0.1
    
    global_k_min -= k_margin
    global_k_max += k_margin
    global_dkdt_min -= dkdt_margin
    global_dkdt_max += dkdt_margin

    # åˆ›å»ºå¤§å›¾ - æ›´å¤§çš„å°ºå¯¸å’Œæ›´é«˜çš„åˆ†è¾¨ç‡
    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows), dpi=200,
                            facecolor='#f8f9fa', constrained_layout=True)

    if rows == 1 and cols == 1:
        axes = np.array([[axes]])
    elif rows == 1:
        axes = axes.reshape(1, -1)
    elif cols == 1:
        axes = axes.reshape(-1, 1)

    # ç¾åŒ–ä¸»æ ‡é¢˜ - ä½¿ç”¨ç°ä»£å­—ä½“å’Œé¢œè‰²
    fig.suptitle('ç³»ç»ŸåŠ¨åŠ›å­¦è¯­ä¹‰æ¼”åŒ–é¢„æµ‹æ¨¡å‹\n(Transformer 12-16å±‚)', fontsize=20,
                fontweight='bold', y=0.98, color='#1f2937')

    # ç°ä»£é…è‰²æ–¹æ¡ˆ
    colors = {
        'actual': '#3b82f6',      # è“è‰² - å®é™…å€¼
        'predicted': '#ef4444',  # çº¢è‰² - é¢„æµ‹å€¼
        'grid': '#e5e7eb',       # æµ…ç°è‰²ç½‘æ ¼
        'background': '#ffffff', # ç™½è‰²èƒŒæ™¯
        'text': '#374151'        # æ·±ç°è‰²æ–‡å­—
    }

    for idx, result in enumerate(all_results):
        row = idx // cols
        col = idx % cols

        token = result['token']
        prediction = result['prediction']
        actual_data = result['actual_data']
        metrics = result['metrics']

        layers = prediction['layers']
        pred_K = prediction['predicted_K']
        pred_dKdt = prediction['predicted_dKdt']

        # æå–å®é™…æ•°æ®
        actual_K = []
        actual_dKdt = []
        for layer in layers:
            actual_row = actual_data[actual_data['å±‚'] == layer]
            if len(actual_row) > 0:
                actual_K.append(actual_row['æ›²ç‡ K(t)'].values[0])
                actual_dKdt.append(actual_row['æ›²ç‡æ¼”åŒ–é€Ÿç‡'].values[0])
            else:
                actual_K.append(np.nan)
                actual_dKdt.append(np.nan)

        ax = axes[row, col]

        # è®¾ç½®å­å›¾èƒŒæ™¯
        ax.set_facecolor(colors['background'])
        ax.patch.set_alpha(0.8)

        # åˆ›å»ºä¸¤ä¸ªå­å›¾ï¼šå·¦è¾¹æ›²ç‡ï¼Œå³è¾¹å˜åŒ–ç‡
        # å·¦åŠéƒ¨åˆ†ï¼šæ›²ç‡ K(t)
        ax_left = ax.inset_axes([0.05, 0.15, 0.4, 0.75])
        ax_left.plot(layers, actual_K, 'o-', color=colors['actual'],
                    label='å®é™…è§‚æµ‹', linewidth=2.5, markersize=8,
                    markerfacecolor='white', markeredgewidth=2.5, markeredgecolor=colors['actual'])
        ax_left.plot(layers, pred_K, 's--', color=colors['predicted'],
                    label='åŠ¨åŠ›å­¦é¢„æµ‹', linewidth=2.5, markersize=8,
                    markerfacecolor='white', markeredgewidth=2.5, markeredgecolor=colors['predicted'])

        # è®¾ç½®å›ºå®šçš„Yè½´èŒƒå›´ï¼ˆåŸºäºå…¨å±€å®é™…è§‚æµ‹å€¼èŒƒå›´ï¼‰
        ax_left.set_ylim(global_k_min, global_k_max)

        ax_left.set_title(f'{token} è¯­ä¹‰æ›²ç‡', fontsize=13, fontweight='bold',
                         color=colors['text'], pad=15)
        ax_left.set_xlabel('å±‚çº§', fontsize=11, color=colors['text'])
        ax_left.set_ylabel('K(t) å€¼', fontsize=11, color=colors['text'])
        ax_left.legend(fontsize=9, frameon=True, fancybox=True, framealpha=0.9,
                      shadow=True, loc='best')
        ax_left.grid(True, alpha=0.4, linestyle='--', color=colors['grid'], linewidth=0.8)
        ax_left.tick_params(axis='both', which='major', labelsize=10, colors=colors['text'])
        ax_left.spines['top'].set_visible(False)
        ax_left.spines['right'].set_visible(False)
        ax_left.spines['left'].set_linewidth(0.8)
        ax_left.spines['bottom'].set_linewidth(0.8)

        # å³åŠéƒ¨åˆ†ï¼šæ›²ç‡æ¼”åŒ–é€Ÿç‡
        ax_right = ax.inset_axes([0.55, 0.15, 0.4, 0.75])
        ax_right.plot(layers, actual_dKdt, 'o-', color=colors['actual'],
                     label='å®é™…è§‚æµ‹', linewidth=2.5, markersize=8,
                     markerfacecolor='white', markeredgewidth=2.5, markeredgecolor=colors['actual'])
        ax_right.plot(layers, pred_dKdt, 's--', color=colors['predicted'],
                     label='åŠ¨åŠ›å­¦é¢„æµ‹', linewidth=2.5, markersize=8,
                     markerfacecolor='white', markeredgewidth=2.5, markeredgecolor=colors['predicted'])

        # è®¾ç½®å›ºå®šçš„Yè½´èŒƒå›´ï¼ˆåŸºäºå…¨å±€å®é™…è§‚æµ‹å€¼èŒƒå›´ï¼‰
        ax_right.set_ylim(global_dkdt_min, global_dkdt_max)

        ax_right.set_title(f'{token} å˜åŒ–ç‡', fontsize=13, fontweight='bold',
                          color=colors['text'], pad=15)
        ax_right.set_xlabel('å±‚çº§', fontsize=11, color=colors['text'])
        ax_right.set_ylabel('æ›²ç‡æ¼”åŒ–é€Ÿç‡', fontsize=11, color=colors['text'])
        ax_right.legend(fontsize=9, frameon=True, fancybox=True, framealpha=0.9,
                       shadow=True, loc='best')
        ax_right.grid(True, alpha=0.4, linestyle='--', color=colors['grid'], linewidth=0.8)
        ax_right.tick_params(axis='both', which='major', labelsize=10, colors=colors['text'])
        ax_right.spines['top'].set_visible(False)
        ax_right.spines['right'].set_visible(False)
        ax_right.spines['left'].set_linewidth(0.8)
        ax_right.spines['bottom'].set_linewidth(0.8)

        # åœ¨åº•éƒ¨æ·»åŠ MAEä¿¡æ¯ - ç°ä»£åŒ–è®¾è®¡
        mae_value = metrics['MAE']
        if mae_value < 0.0005:
            mae_color = '#10b981'  # ç»¿è‰² - ä¼˜ç§€
            mae_status = 'ä¼˜ç§€'
        elif mae_value < 0.001:
            mae_color = '#f59e0b'  # æ©™è‰² - è‰¯å¥½
            mae_status = 'è‰¯å¥½'
        else:
            mae_color = '#ef4444'  # çº¢è‰² - éœ€è¦æ”¹è¿›
            mae_status = 'éœ€æ”¹è¿›'

        # æ·»åŠ MAEä¿¡æ¯æ¡†
        ax.text(0.5, 0.02, f'{mae_status} MAE: {mae_value:.6f}',
                ha='center', va='bottom', transform=ax.transAxes,
                fontsize=12, fontweight='bold', color=mae_color,
                bbox=dict(boxstyle='round,pad=0.5', facecolor='white',
                         edgecolor=mae_color, linewidth=2, alpha=0.95))

        # éšè—ä¸»è½´
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)

        # æ·»åŠ å­å›¾è¾¹æ¡†
        for spine in ax.spines.values():
            spine.set_visible(False)

    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(n_tokens, rows * cols):
        row = idx // cols
        col = idx % cols
        axes[row, col].set_visible(False)

    # æ·»åŠ åº•éƒ¨è¯´æ˜
    fig.text(0.5, 0.02,
            'åŸºäºç³»ç»ŸåŠ¨åŠ›å­¦å¢å¼º-è°ƒèŠ‚å›è·¯æ¨¡å‹ | è“è‰²åœ†åœˆï¼šå®é™…è§‚æµ‹ | çº¢è‰²æ–¹å—ï¼šåŠ¨åŠ›å­¦é¢„æµ‹',
            ha='center', fontsize=11, color='#6b7280',
            style='italic')

    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='#f8f9fa', pad_inches=0.5)
    plt.close()

    print(f"ğŸ¨ ç°ä»£åŒ–ç¾åŒ–ç»¼åˆå¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}")
    n_tokens = len(all_results)
    if n_tokens == 0:
        return

    # è®¡ç®—å­å›¾å¸ƒå±€ (å°½é‡æ¥è¿‘æ­£æ–¹å½¢)
    cols = int(np.ceil(np.sqrt(n_tokens)))
    rows = int(np.ceil(n_tokens / cols))

    # åˆ›å»ºå¤§å›¾ - æ›´å¤§çš„å°ºå¯¸å’Œæ›´é«˜çš„åˆ†è¾¨ç‡
    fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 5*rows), dpi=150)
    if rows == 1 and cols == 1:
        axes = np.array([[axes]])
    elif rows == 1:
        axes = axes.reshape(1, -1)
    elif cols == 1:
        axes = axes.reshape(-1, 1)

    # ç¾åŒ–ä¸»æ ‡é¢˜
    fig.suptitle('ç³»ç»ŸåŠ¨åŠ›å­¦å¢å¼º-è°ƒèŠ‚å›è·¯æ¨¡å‹ï¼šå¥å­è¯­ä¹‰æ¼”åŒ–é¢„æµ‹\n(12-16å±‚)', fontsize=18, fontweight='bold', y=0.98, color='#2E3440')

    for idx, result in enumerate(all_results):
        row = idx // cols
        col = idx % cols

        token = result['token']
        prediction = result['prediction']
        actual_data = result['actual_data']
        metrics = result['metrics']

        layers = prediction['layers']
        pred_K = prediction['predicted_K']
        pred_dKdt = prediction['predicted_dKdt']

        # æå–å®é™…æ•°æ®
        actual_K = []
        actual_dKdt = []
        for layer in layers:
            actual_row = actual_data[actual_data['å±‚'] == layer]
            if len(actual_row) > 0:
                actual_K.append(actual_row['æ›²ç‡ K(t)'].values[0])
                actual_dKdt.append(actual_row['æ›²ç‡æ¼”åŒ–é€Ÿç‡'].values[0])
            else:
                actual_K.append(np.nan)
                actual_dKdt.append(np.nan)

        ax = axes[row, col]

        # åœ¨åŒä¸€å­å›¾ä¸­ç»˜åˆ¶ä¸¤ä¸ªå›¾è¡¨ï¼ˆä¸Šä¸‹æ’åˆ—ï¼‰- ç¾åŒ–ç‰ˆæœ¬
        # ä¸ŠåŠéƒ¨åˆ†ï¼šæ›²ç‡ - ä½¿ç”¨æ›´ç¾è§‚çš„æ ·å¼
        ax_top = ax.inset_axes([0.08, 0.55, 0.88, 0.4])  # è°ƒæ•´è¾¹è·
        ax_top.plot(layers, actual_K, 'o-', color='#5E81AC', label='å®é™…è§‚æµ‹', linewidth=2, markersize=6, markerfacecolor='white', markeredgewidth=2)
        ax_top.plot(layers, pred_K, 's--', color='#BF616A', label='ç³»ç»ŸåŠ¨åŠ›å­¦é¢„æµ‹', linewidth=2, markersize=6, markerfacecolor='white', markeredgewidth=2)
        ax_top.set_title(f'{token} - è¯­ä¹‰æ›²ç‡ K(t)', fontsize=12, fontweight='bold', color='#2E3440', pad=10)
        ax_top.set_ylabel('æ›²ç‡å€¼', fontsize=10, color='#4C566A')
        ax_top.legend(fontsize=9, frameon=True, fancybox=True, shadow=True, loc='upper right')
        ax_top.grid(True, alpha=0.3, linestyle='--', color='#D8DEE9')
        ax_top.tick_params(axis='both', which='major', labelsize=9, colors='#4C566A')
        ax_top.spines['top'].set_visible(False)
        ax_top.spines['right'].set_visible(False)

        # ä¸‹åŠéƒ¨åˆ†ï¼šæ›²ç‡å˜åŒ–ç‡ - ä½¿ç”¨æ›´ç¾è§‚çš„æ ·å¼
        ax_bottom = ax.inset_axes([0.08, 0.05, 0.88, 0.4])  # è°ƒæ•´è¾¹è·
        ax_bottom.plot(layers, actual_dKdt, 'o-', color='#5E81AC', label='å®é™…è§‚æµ‹', linewidth=2, markersize=6, markerfacecolor='white', markeredgewidth=2)
        ax_bottom.plot(layers, pred_dKdt, 's--', color='#BF616A', label='ç³»ç»ŸåŠ¨åŠ›å­¦é¢„æµ‹', linewidth=2, markersize=6, markerfacecolor='white', markeredgewidth=2)
        ax_bottom.set_title(f'{token} - æ›²ç‡æ¼”åŒ–é€Ÿç‡', fontsize=12, fontweight='bold', color='#2E3440', pad=10)
        ax_bottom.set_xlabel('Transformerå±‚', fontsize=10, color='#4C566A')
        ax_bottom.set_ylabel('å˜åŒ–ç‡', fontsize=10, color='#4C566A')
        ax_bottom.legend(fontsize=9, frameon=True, fancybox=True, shadow=True, loc='upper right')
        ax_bottom.grid(True, alpha=0.3, linestyle='--', color='#D8DEE9')
        ax_bottom.tick_params(axis='both', which='major', labelsize=9, colors='#4C566A')
        ax_bottom.spines['top'].set_visible(False)
        ax_bottom.spines['right'].set_visible(False)

        # åœ¨å­å›¾åº•éƒ¨æ·»åŠ è¯¯å·®ä¿¡æ¯ - ç¾åŒ–ç‰ˆæœ¬
        mae_color = '#A3BE8C' if metrics['MAE'] < 0.0005 else '#EBCB8B' if metrics['MAE'] < 0.001 else '#BF616A'
        ax.text(0.5, 0.02, f'MAE: {metrics["MAE"]:.6f}', ha='center', va='bottom',
                transform=ax.transAxes, fontsize=10, fontweight='bold', color=mae_color,
                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor=mae_color, linewidth=2, alpha=0.9))

        # éšè—ä¸»è½´
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)

    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(n_tokens, rows * cols):
        row = idx // cols
        col = idx % cols
        axes[row, col].set_visible(False)

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    plt.subplots_adjust(top=0.92, hspace=0.3, wspace=0.2)
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"ğŸ¨ ç°ä»£åŒ–ç¾åŒ–ç»¼åˆå¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}")

# ====================== ä¸»å‡½æ•° ======================
def main():
    # è®¾ç½®è·¯å¾„
    ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    data_path = os.path.join(ROOT, 'sd', 'feedback', 'layers_0_23_batch_core_variables.csv')
    output_dir = os.path.join(ROOT, 'sd', 'reinforcing_balancing_loops')

    # ==================== å‚æ•°ä¼˜åŒ– ====================
    print("="*70)
    print("å‚æ•°ä¼˜åŒ–é˜¶æ®µ")
    print("="*70)

    # ä½¿ç”¨çœŸå®æ•°æ®ä¼˜åŒ–å‚æ•°
    try:
        optimized_params, final_mae = optimize_parameters(data_path)  # ä½¿ç”¨æ‰€æœ‰å¥å­

        # æ›´æ–°å…¨å±€å‚æ•°
        global R1_GAIN, B1_SEMANTIC_GAIN, B2_DISTANCE_GAIN
        R1_GAIN = optimized_params[0]
        B1_SEMANTIC_GAIN = optimized_params[1]
        B2_DISTANCE_GAIN = optimized_params[2]

        print(f"\\nå‚æ•°å·²æ›´æ–°ä¸ºä¼˜åŒ–å€¼ï¼")
        print(f"ä¼˜åŒ–åMAE: {final_mae:.6f}")

    except Exception as e:
        print(f"å‚æ•°ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°: {e}")
        # ä¿æŒé»˜è®¤å‚æ•°ä¸å˜

    print("\\n" + "="*70)
    print("æ¨¡å‹é¢„æµ‹é˜¶æ®µ")
    print("="*70)

    # è¯»å–æ•°æ®
    df = pd.read_csv(data_path)

    # æµ‹è¯•å¥å­åˆ—è¡¨
    test_sentences = [
        'æ±Ÿæ²³æ¹–æµ·éƒ½æ˜¯æ°´',
        "ç‰›åœ¨ç”°é‡Œåƒè‰ã€‚",
        "ç¾Šå–œæ¬¢åœ¨å±±å¡ä¸Šæ´»åŠ¨ã€‚",
        "é±¼åœ¨æ°´é‡Œæ¸¸æ¥æ¸¸å»ã€‚",
        "é¸Ÿåœ¨æ ‘æä¸Šå”±æ­Œã€‚",
        "é©¬åœ¨è‰åŸä¸Šå¥”è·‘ã€‚",
        "è™åœ¨æ—ä¸­ä¼‘æ¯ã€‚"
    ]

    # ä¸ºæ¯ä¸ªå¥å­è¿›è¡Œé¢„æµ‹
    for sentence in test_sentences:
        print(f"\n{'='*70}")
        print(f"å¤„ç†å¥å­: {sentence}")
        print(f"{'='*70}")

        df_sentence = df[df['å¥å­'] == sentence]

        # æ£€æŸ¥å¥å­æ˜¯å¦å­˜åœ¨äºæ•°æ®ä¸­
        if df_sentence.empty:
            print(f"è­¦å‘Š: å¥å­ '{sentence}' åœ¨æ•°æ®ä¸­ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue

        # è·å–æ‰€æœ‰token
        tokens = df_sentence['Token'].unique()

        print(f"æµ‹è¯•å¥å­: {sentence}")
        print(f"é¢„æµ‹å±‚èŒƒå›´: 12-16")
        print("å›è·¯å‚æ•°:")
        print(f"  å¢å¼ºå›è·¯å¢ç›Š R1 = {R1_GAIN}")
        print(f"  è°ƒèŠ‚å›è·¯B1å¢ç›Š (è¯­ä¹‰) = {B1_SEMANTIC_GAIN}")
        print(f"  è°ƒèŠ‚å›è·¯B2å¢ç›Š (è·ç¦») = {B2_DISTANCE_GAIN}")
        print(f"  åé¦ˆå»¶è¿Ÿ = {FEEDBACK_DELAY}")
        print()

        # ä¸ºæ¯ä¸ªtokenè¿›è¡Œé¢„æµ‹
        all_results = []
        for token in tokens:  # å¤„ç†æ‰€æœ‰token
            print(f"\nå¤„ç†token: {token}")

            token_data = df_sentence[df_sentence['Token'] == token]
            prediction = loop_based_predict(token_data)

            if prediction is None:
                print(f"  è·³è¿‡token {token} (ç¼ºå°‘ç¬¬9å±‚æ•°æ®)")
                continue

            # åˆ†æå›è·¯åŠ¨æ€
            analyze_loop_dynamics(token_data, prediction)

            # è¯„ä¼°é¢„æµ‹è´¨é‡
            metrics = evaluate_predictions(token_data, prediction)

            print(f"  é¢„æµ‹è¯¯å·®: MSE={metrics['MSE']:.6f}, MAE={metrics['MAE']:.6f}, MAPE={metrics['MAPE']:.3f}")

            all_results.append({
                'token': token,
                'metrics': metrics,
                'prediction': prediction,
                'actual_data': token_data
            })

        # ç”Ÿæˆç»¼åˆå›¾è¡¨ï¼ˆæ‰€æœ‰tokenåœ¨ä¸€å¼ å›¾ä¸Šï¼‰
        if all_results:
            # åˆ›å»ºåŒ…å«å¥å­å’Œå±‚èŒƒå›´çš„å›¾ç‰‡æ–‡ä»¶å
            sentence_clean = sentence.replace('ã€‚', '').replace('ï¼Œ', '').replace(' ', '_')[:20]  # æ¸…ç†å¥å­ç”¨äºæ–‡ä»¶å
            combined_plot_path = os.path.join(output_dir, f'{sentence_clean}_layers_{12}_{16}_comparison.png')
            plot_all_tokens_comparison(all_results, combined_plot_path)

    # ä¿å­˜æ¨¡å‹å‚æ•°
    model_config = {
        'model_type': 'reinforcing_balancing_loops_system_dynamics',
        'parameters': {
            'R1_GAIN': R1_GAIN,
            'B1_SEMANTIC_GAIN': B1_SEMANTIC_GAIN,
            'B1_SEMANTIC_DELAY': B1_SEMANTIC_DELAY,
            'B2_DISTANCE_GAIN': B2_DISTANCE_GAIN,
            'B2_DISTANCE_THRESHOLD': B2_DISTANCE_THRESHOLD,
            'FEEDBACK_DELAY': FEEDBACK_DELAY
        },
        'description': 'åŸºäºç³»ç»ŸåŠ¨åŠ›å­¦å¢å¼ºå›è·¯å’Œè°ƒèŠ‚å›è·¯ç»„åˆçš„è¯­ä¹‰æ¼”åŒ–é¢„æµ‹æ¨¡å‹',
        'loop_structure': {
            'R1': 'å¢å¼ºå›è·¯ï¼šå‰å±‚èšåˆé©±åŠ¨åå±‚èšåˆ',
            'B1': 'è°ƒèŠ‚å›è·¯ï¼šè¯­ä¹‰ç¨³å®šæ€§æŠ‘åˆ¶è¿‡åº¦èšåˆ',
            'B2': 'è°ƒèŠ‚å›è·¯ï¼šè·ç¦»å˜åŒ–å¢åŠ èšåˆé˜»åŠ›'
        }
    }

    config_path = os.path.join(output_dir, 'loop_model_config.json')
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(model_config, f, indent=2, ensure_ascii=False)

    print(f"\\nå›è·¯æ¨¡å‹é…ç½®å·²ä¿å­˜åˆ°: {config_path}")
    print("\\nç³»ç»ŸåŠ¨åŠ›å­¦å¢å¼º-è°ƒèŠ‚å›è·¯æ¨¡å‹æµ‹è¯•å®Œæˆï¼")

# ====================== è¯„ä¼°å‡½æ•° ======================
def evaluate_predictions(actual_data, predicted_data):
    """
    è¯„ä¼°é¢„æµ‹ç»“æœçš„è´¨é‡
    """
    layers = predicted_data['layers']
    pred_K = predicted_data['predicted_K']

    mse = 0
    mae = 0
    mape = 0
    count = 0

    for i, layer in enumerate(layers):
        actual_row = actual_data[actual_data['å±‚'] == layer]
        if len(actual_row) > 0:
            actual_K = actual_row['æ›²ç‡ K(t)'].values[0]
            pred_K_val = pred_K[i]

            error = pred_K_val - actual_K
            mse += error ** 2
            mae += abs(error)
            mape += abs(error) / abs(actual_K) if actual_K != 0 else 0
            count += 1

    if count > 0:
        mse /= count
        mae /= count
        mape /= count

    return {
        'MSE': mse,
        'MAE': mae,
        'MAPE': mape,
        'Sample_Count': count
    }

# ====================== å‚æ•°ä¼˜åŒ–åŠŸèƒ½ ======================
def load_real_data(data_path):
    """
    åŠ è½½çœŸå®æ•°æ®ç”¨äºå‚æ•°ä¼˜åŒ–
    """
    df = pd.read_csv(data_path)
    print(f"åŠ è½½çœŸå®æ•°æ®: {len(df)} æ¡è®°å½•ï¼Œ{df['å¥å­'].nunique()} ä¸ªå¥å­")

    # æŒ‰å¥å­åˆ†ç»„å¤„ç†
    sentence_groups = {}
    for sentence in df['å¥å­'].unique():
        sentence_data = df[df['å¥å­'] == sentence]
        sentence_groups[sentence] = sentence_data

    return sentence_groups

def objective_function(params, real_data_groups, target_sentences=None):
    """
    å‚æ•°ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ–å¤šä¸ªå¥å­çš„å¹³å‡MAE
    """
    # è§£åŒ…å‚æ•°
    r1_gain, b1_gain, b2_gain = params

    # æ›´æ–°å…¨å±€å‚æ•°ï¼ˆä¸´æ—¶ï¼‰
    global R1_GAIN, B1_SEMANTIC_GAIN, B2_DISTANCE_GAIN
    original_r1 = R1_GAIN
    original_b1 = B1_SEMANTIC_GAIN
    original_b2 = B2_DISTANCE_GAIN

    R1_GAIN = r1_gain
    B1_SEMANTIC_GAIN = b1_gain
    B2_DISTANCE_GAIN = b2_gain

    try:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå¥å­ï¼Œä½¿ç”¨æ‰€æœ‰å¥å­
        if target_sentences is None:
            target_sentences = list(real_data_groups.keys())

        total_sentences_mae = 0
        valid_sentences = 0

        for sentence in target_sentences:
            if sentence not in real_data_groups:
                continue

            sentence_data = real_data_groups[sentence]

            # ä¸ºè¯¥å¥å­çš„æ‰€æœ‰tokenè¿›è¡Œé¢„æµ‹å¹¶è®¡ç®—å¹³å‡MAE
            tokens = sentence_data['Token'].unique()[:3]  # ä½¿ç”¨å‰3ä¸ªtoken
            total_sentence_mae = 0
            token_count = 0

            for token in tokens:
                token_data = sentence_data[sentence_data['Token'] == token]

                # è¿è¡Œé¢„æµ‹
                predicted_data = loop_based_predict(token_data)
                if predicted_data is None:
                    continue

                # è®¡ç®—è¯¥tokençš„MAE
                layers = predicted_data['layers']
                pred_K = predicted_data['predicted_K']

                token_mae = 0
                count = 0

                for i, layer in enumerate(layers):
                    actual_row = token_data[token_data['å±‚'] == layer]
                    if len(actual_row) > 0:
                        actual_K = actual_row['æ›²ç‡ K(t)'].values[0]
                        pred_K_val = pred_K[i]

                        # è®¡ç®—MAEï¼ˆå¹³å‡ç»å¯¹è¯¯å·®ï¼‰
                        mae = abs(pred_K_val - actual_K)
                        token_mae += mae
                        count += 1

                if count > 0:
                    token_mae /= count
                    total_sentence_mae += token_mae
                    token_count += 1

            if token_count > 0:
                sentence_avg_mae = total_sentence_mae / token_count
                total_sentences_mae += sentence_avg_mae
                valid_sentences += 1

        if valid_sentences > 0:
            avg_mae = total_sentences_mae / valid_sentences
        else:
            avg_mae = 1.0

        # è°ƒè¯•è¾“å‡ºï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶æ˜¾ç¤ºï¼‰
        if not hasattr(objective_function, 'call_count'):
            objective_function.call_count = 0
        objective_function.call_count += 1
        if objective_function.call_count % 10 == 1:  # æ¯10æ¬¡è°ƒç”¨æ˜¾ç¤ºä¸€æ¬¡
            print(f"  ç›®æ ‡å‡½æ•°è°ƒç”¨ #{objective_function.call_count}: params=[{r1_gain:.3f}, {b1_gain:.3f}, {b2_gain:.3f}], MAE={avg_mae:.6f}")

    except Exception as e:
        print(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        avg_mae = 1.0
    finally:
        # æ¢å¤åŸå§‹å‚æ•°
        R1_GAIN = original_r1
        B1_SEMANTIC_GAIN = original_b1
        B2_DISTANCE_GAIN = original_b2

    return avg_mae

def optimize_parameters(real_data_path, target_sentences=None, max_sentences=5):
    """
    ä½¿ç”¨çœŸå®æ•°æ®ä¼˜åŒ–æ¨¡å‹å‚æ•°
    æ”¯æŒä½¿ç”¨å¤šä¸ªå¥å­è¿›è¡Œæ›´å…¨é¢çš„ä¼˜åŒ–
    """
    print("å¼€å§‹å‚æ•°ä¼˜åŒ–...")

    # åŠ è½½æ•°æ®
    real_data_groups = load_real_data(real_data_path)

    # é€‰æ‹©ç”¨äºä¼˜åŒ–çš„å¥å­
    if target_sentences is None:
        # ä½¿ç”¨æ‰€æœ‰å¯ç”¨å¥å­è¿›è¡Œä¼˜åŒ–
        available_sentences = list(real_data_groups.keys())
        target_sentences = available_sentences  # ä½¿ç”¨æ‰€æœ‰å¥å­

    print(f"ä½¿ç”¨ {len(target_sentences)} ä¸ªå¥å­è¿›è¡Œå‚æ•°ä¼˜åŒ–")

    # å‚æ•°èŒƒå›´ï¼ˆæ‰©å¤§èŒƒå›´ä»¥è·å¾—æ›´å¥½çš„ä¼˜åŒ–ï¼‰
    bounds = [
        (0.01, 2.0),   # R1_GAIN
        (0.01, 2.0),   # B1_SEMANTIC_GAIN
        (0.01, 2.0)    # B2_DISTANCE_GAIN
    ]

    # åˆå§‹å‚æ•°
    initial_params = [R1_GAIN, B1_SEMANTIC_GAIN, B2_DISTANCE_GAIN]

    print(f"åˆå§‹å‚æ•°: R1={initial_params[0]:.3f}, B1={initial_params[1]:.3f}, B2={initial_params[2]:.3f}")

    # å°è¯•å¤šç§åˆå§‹ç‚¹è¿›è¡Œä¼˜åŒ–
    initial_points = [
        [0.6, 0.3, 0.2],  # å½“å‰é»˜è®¤å€¼
        [0.8, 0.4, 0.3],  # æ›´é«˜çš„å€¼
        [0.4, 0.2, 0.1],  # æ›´ä½çš„å€¼
        [1.0, 0.5, 0.4],  # æ›´é«˜å€¼
        [0.2, 0.1, 0.05], # æ›´ä½å€¼
    ]

    best_result = None
    best_mape = float('inf')

    for i, init_params in enumerate(initial_points):
        print(f"\\nå°è¯•åˆå§‹ç‚¹ {i+1}: {init_params}")

        try:
            result = minimize(
                objective_function,
                init_params,
                args=(real_data_groups, target_sentences),
                bounds=bounds,
                method='SLSQP',  # æ”¹ç”¨SLSQPæ–¹æ³•
                options={'maxiter': 100, 'disp': False}
            )

            if result.success and result.fun < best_mape:
                best_result = result
                best_mape = result.fun
                print(f"  æ–°çš„æœ€ä½³MAPE: {best_mape:.4f}")

        except Exception as e:
            print(f"  åˆå§‹ç‚¹ {i+1} ä¼˜åŒ–å¤±è´¥: {e}")
            continue

    if best_result is None:
        print("æ‰€æœ‰ä¼˜åŒ–å°è¯•éƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
        final_mae = objective_function(initial_params, real_data_groups, target_sentence)
        return initial_params, final_mae

    result = best_result

    # è¾“å‡ºè¯¦ç»†ç»“æœ
    print(f"\\nä¼˜åŒ–è¯¦ç»†ä¿¡æ¯:")
    print(f"  è¿­ä»£æ¬¡æ•°: {result.nit}")
    print(f"  å‡½æ•°è°ƒç”¨æ¬¡æ•°: {result.nfev}")
    print(f"  æ”¶æ•›çŠ¶æ€: {result.success}")
    print(f"  æ”¶æ•›æ¶ˆæ¯: {result.message}")

    # è¾“å‡ºç»“æœ
    optimized_params = result.x
    final_mae = result.fun

    print(f"\\nä¼˜åŒ–ç»“æœ:")
    print(f"  æœ€ç»ˆMAE: {final_mae:.6f}")
    print(f"  ä¼˜åŒ–å‚æ•°: R1={optimized_params[0]:.4f}, B1={optimized_params[1]:.4f}, B2={optimized_params[2]:.4f}")
    print(f"  ä¼˜åŒ–æˆåŠŸ: {result.success}")

    # æ£€æŸ¥å‚æ•°å˜åŒ–
    param_change = np.abs(np.array(optimized_params) - np.array(initial_params))
    print(f"  å‚æ•°å˜åŒ–: R1={param_change[0]:.6f}, B1={param_change[1]:.6f}, B2={param_change[2]:.6f}")

    if np.max(param_change) < 1e-6:
        print("  æ³¨æ„ï¼šå‚æ•°å‡ ä¹æ²¡æœ‰å˜åŒ–ï¼Œå¯èƒ½å·²è¾¾åˆ°å±€éƒ¨æœ€ä¼˜æˆ–éœ€è¦è°ƒæ•´ä¼˜åŒ–è®¾ç½®")

    return optimized_params, final_mae

if __name__ == "__main__":
    main()