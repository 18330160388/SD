"""
S(t) Î¼å‚æ•°æ¶ˆèå®éªŒ

æµ‹è¯•ä¸åŒÎ¼å€¼å¯¹è¯­ä¹‰æ¼‚ç§»ç³»æ•°S(t)çš„å½±å“
Î¼æ˜¯å½¢æ€ä¿®æ­£å› å­Î¾(M(t)) = 1 - Î¼Â·M(t)ä¸­çš„æƒé‡ç³»æ•°

å®éªŒè¾“å‡º:
- ç»Ÿè®¡è¡¨æ ¼
- è¶‹åŠ¿å›¾è¡¨
- è¯¦ç»†åˆ†ææŠ¥å‘Š
"""

import torch
import sys
import os
import numpy as np
import pandas as pd
from typing import Dict, List
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
# å½“å‰æ–‡ä»¶: experiments/S/S_t_test.py
# é¡¹ç›®æ ¹ç›®å½•: ../../
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(project_root)
print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")

# ç›´æ¥å¯¼å…¥æ¨¡å—
sys.path.append(os.path.join(project_root, 'SD'))
from s_t_calculator import SemanticDriftCoeff

class MuAblationExperiment:
    """S(t) Î¼å‚æ•°æ¶ˆèå®éªŒ"""

    def __init__(self):
        # Î¼å€¼èŒƒå›´ï¼šåŸºäºå…¸å‹å€¼0.25ï¼Œæµ‹è¯•å‘¨å›´èŒƒå›´
        self.mu_values = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5]
        self.test_sentences = [
            "æ±Ÿæ²³æ¹–æµ·éƒ½æ˜¯æ°´",
            "å°çŒ«è¿½ç€è´è¶è·‘è¿‡èŠ±å›­",
            "ç§‘å­¦å®¶åœ¨å®éªŒå®¤ç ”ç©¶æ–°å‹ç–«è‹—",
            "å­¦ç”Ÿä»¬è®¤çœŸå¬è€å¸ˆè®²è¯¾"
        ]
        self.results = defaultdict(dict)

    def run_experiment(self):
        """è¿è¡Œæ¶ˆèå®éªŒ"""
        print("=" * 80)
        print("S(t) Î¼å‚æ•°æ¶ˆèå®éªŒ")
        print("=" * 80)
        print(f"æµ‹è¯•Î¼å€¼: {self.mu_values}")
        print(f"æµ‹è¯•å¥å­æ•°é‡: {len(self.test_sentences)}")
        print()

        for sentence_idx, sentence in enumerate(self.test_sentences):
            print(f"å¤„ç†å¥å­ {sentence_idx + 1}/{len(self.test_sentences)}: {sentence}")
            print("-" * 60)

            # å¯¹æ¯ä¸ªÎ¼å€¼è¿›è¡Œæµ‹è¯•
            for mu in self.mu_values:
                print(f"\næµ‹è¯• Î¼ = {mu}")
                print("-" * 30)

                # åˆ›å»ºè®¡ç®—å™¨å®ä¾‹ï¼Œè®¾ç½®ä¸åŒçš„Î¼å€¼
                calculator = SemanticDriftCoeff(lambda_decay=0.1)
                # æ‰‹åŠ¨è®¾ç½®Î¼å‚æ•°ï¼ˆå› ä¸ºå®ƒæ˜¯nn.Parameterï¼‰
                with torch.no_grad():
                    calculator.mu.fill_(mu)

                try:
                    # è®¡ç®—S(t)
                    s_t_values = calculator(sentence)

                    # è½¬æ¢ä¸ºnumpyæ•°ç»„ä»¥ä¾¿ç»Ÿè®¡
                    s_t_array = s_t_values.detach().cpu().numpy()

                    # ç»Ÿè®¡ç»“æœ
                    stats = {
                        'sentence': sentence,
                        'sentence_idx': sentence_idx,
                        'mu': mu,
                        's_t_values': s_t_array.tolist(),
                        's_t_mean': float(np.mean(s_t_array)),
                        's_t_std': float(np.std(s_t_array)),
                        's_t_max': float(np.max(s_t_array)),
                        's_t_min': float(np.min(s_t_array)),
                        's_t_range': float(np.max(s_t_array) - np.min(s_t_array)),
                        'seq_len': len(s_t_array)
                    }

                    self.results[mu][sentence] = stats

                    print(f"ç»Ÿè®¡ç»“æœ:")
                    print(f"  S(t) - å‡å€¼: {stats['s_t_mean']:.6f}, æ ‡å‡†å·®: {stats['s_t_std']:.6f}")
                    print(f"  S(t) - èŒƒå›´: [{stats['s_t_min']:.6f}, {stats['s_t_max']:.6f}]")
                    print(f"  åºåˆ—é•¿åº¦: {stats['seq_len']}")

                except Exception as e:
                    print(f"  é”™è¯¯å¤„ç†å¥å­ '{sentence}' with Î¼={mu}: {e}")
                    # åˆ›å»ºé»˜è®¤çš„é”™è¯¯ç»Ÿè®¡
                    stats = {
                        'sentence': sentence,
                        'sentence_idx': sentence_idx,
                        'mu': mu,
                        's_t_values': [],
                        's_t_mean': 0.0,
                        's_t_std': 0.0,
                        's_t_max': 0.0,
                        's_t_min': 0.0,
                        's_t_range': 0.0,
                        'seq_len': 0
                    }
                    self.results[mu][sentence] = stats

            print()

        print("å®éªŒå®Œæˆï¼")
        return self.results

    def generate_summary_table(self):
        """ç”Ÿæˆæ±‡æ€»è¡¨æ ¼"""
        print("\n" + "=" * 80)
        print("å®éªŒç»“æœæ±‡æ€»è¡¨")
        print("=" * 80)

        # åˆ›å»ºæ±‡æ€»æ•°æ®
        summary_data = []
        for mu in self.mu_values:
            mu_stats = []
            for sentence in self.test_sentences:
                if sentence in self.results[mu]:
                    stats = self.results[mu][sentence]
                    mu_stats.append({
                        'sentence': sentence,
                        's_t_mean': stats['s_t_mean'],
                        's_t_std': stats['s_t_std'],
                        's_t_range': stats['s_t_range'],
                        'seq_len': stats['seq_len']
                    })

            if mu_stats:
                # è®¡ç®—Î¼çš„æ•´ä½“ç»Ÿè®¡
                s_t_means = [s['s_t_mean'] for s in mu_stats]
                s_t_stds = [s['s_t_std'] for s in mu_stats]
                s_t_ranges = [s['s_t_range'] for s in mu_stats]
                seq_lens = [s['seq_len'] for s in mu_stats]

                summary_data.append({
                    'Î¼': mu,
                    'S(t)_Mean': f"{np.mean(s_t_means):.6f}",
                    'S(t)_Std': f"{np.mean(s_t_stds):.6f}",
                    'S(t)_Range_Mean': f"{np.mean(s_t_ranges):.6f}",
                    'Avg_Seq_Len': f"{np.mean(seq_lens):.1f}",
                    'Sentence_Count': len(mu_stats)
                })

        # æ‰“å°è¡¨æ ¼
        if summary_data:
            df = pd.DataFrame(summary_data)
            print(df.to_string(index=False))

            # ä¿å­˜åˆ°CSVï¼ˆä¿å­˜åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•ï¼‰
            script_dir = os.path.dirname(os.path.abspath(__file__))
            csv_path = os.path.join(script_dir, 'S_mu_ablation_summary.csv')
            df.to_csv(csv_path, index=False)
            print(f"\næ±‡æ€»è¡¨å·²ä¿å­˜åˆ°: {csv_path}")

        return summary_data

    def plot_results(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆå·²ç¦ç”¨ï¼‰"""
        print("\n" + "=" * 80)
        print("è·³è¿‡å›¾è¡¨ç”Ÿæˆï¼ˆæ ¹æ®ç”¨æˆ·è¦æ±‚ï¼‰")
        print("=" * 80)
        print("å¦‚éœ€æŸ¥çœ‹å›¾è¡¨ï¼Œè¯·å–æ¶ˆæ³¨é‡Šç›¸å…³ä»£ç ")

    def analyze_optimal_mu(self):
        """åˆ†ææœ€ä¼˜Î¼å€¼"""
        print("\n" + "=" * 80)
        print("æœ€ä¼˜Î¼å€¼åˆ†æ")
        print("=" * 80)

        # é‡æ–°è®¾è®¡è¯„åˆ†æœºåˆ¶ï¼šè€ƒè™‘è¯­ä¹‰æ¼‚ç§»çš„åˆç†æ€§å’Œå¹³è¡¡æ€§
        mu_scores = {}

        for mu in self.mu_values:
            scores = []

            for sentence in self.test_sentences:
                if sentence in self.results[mu]:
                    stats = self.results[mu][sentence]

                    # 1. S(t)å€¼åˆç†æ€§ï¼šåº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆæƒé‡0.3ï¼‰
                    # ç†æƒ³èŒƒå›´ï¼š[0.1, 0.8]ï¼Œè¿‡å¤§æˆ–è¿‡å°éƒ½ä¸å¥½
                    mean_reasonable = 1.0 - abs(stats['s_t_mean'] - 0.4) / 0.4  # 0.4ä¸ºä¸­å¿ƒ
                    range_reasonable = min(stats['s_t_range'], 1.0) / 1.0  # èŒƒå›´ä¸åº”è¯¥è¿‡å¤§
                    reasonable_score = (mean_reasonable + range_reasonable) / 2.0

                    # 2. ç¨³å®šæ€§ï¼šæ ‡å‡†å·®ä¸åº”è¯¥è¿‡å¤§ï¼ˆæƒé‡0.3ï¼‰
                    stability_score = 1.0 / (1.0 + stats['s_t_std'])

                    # 3. åŒºåˆ†åº¦ï¼šèŒƒå›´åº”è¯¥é€‚ä¸­ï¼ˆæƒé‡0.2ï¼‰
                    # å¤ªå°çš„èŒƒå›´è¡¨ç¤ºç¼ºä¹åŒºåˆ†åº¦ï¼Œå¤ªå¤§çš„èŒƒå›´è¡¨ç¤ºè¿‡äºæ•æ„Ÿ
                    optimal_range = 0.3
                    range_score = 1.0 - abs(stats['s_t_range'] - optimal_range) / optimal_range

                    # 4. Î¼åˆç†æ€§æƒ©ç½šï¼šè¿‡å¤§çš„Î¼åº”è¯¥è¢«æƒ©ç½šï¼ˆæƒé‡0.2ï¼‰
                    # Î¼åœ¨[0.2, 0.4]èŒƒå›´å†…ï¼Œ0.25å·¦å³å¯èƒ½æ˜¯æœ€åˆç†çš„
                    mu_penalty = 1.0 - abs(mu - 0.25) / 0.25  # 0.25ä¸ºä¸­å¿ƒ
                    mu_penalty = max(mu_penalty, 0.1)  # æœ€å°æƒ©ç½š

                    # ç»¼åˆè¯„åˆ†
                    score = (reasonable_score * 0.3 +
                           stability_score * 0.3 +
                           range_score * 0.2 +
                           mu_penalty * 0.2)

                    scores.append(score)

            if scores:
                mu_scores[mu] = np.mean(scores)

        # æ’åºå¹¶è¾“å‡º
        sorted_mus = sorted(mu_scores.items(), key=lambda x: x[1], reverse=True)

        print("Î¼å€¼ç»¼åˆè¯„åˆ† (è€ƒè™‘å¹³è¡¡æ€§å’Œåˆç†æ€§):")
        print("-" * 50)
        for mu, score in sorted_mus:
            print(".2f")

        optimal_mu = sorted_mus[0][0]
        print(f"\næ¨èæœ€ä¼˜Î¼å€¼: {optimal_mu}")
        print("é€‰æ‹©ç†ç”±:")
        print(f"- ç»¼åˆè¯„åˆ†æœ€é«˜ ({mu_scores[optimal_mu]:.4f})")
        print("- åœ¨è¯­ä¹‰æ¼‚ç§»åˆç†æ€§ã€ç¨³å®šæ€§å’ŒåŒºåˆ†åº¦é—´å–å¾—æœ€ä½³å¹³è¡¡")
        print("- é¿å…è¿‡åº¦æ”¾å¤§å½¢æ€ä¿®æ­£å¯¼è‡´çš„ä¸åˆç†æ¼‚ç§»ç³»æ•°")

        return optimal_mu

def main():
    """ä¸»å‡½æ•°"""
    experiment = MuAblationExperiment()

    # è¿è¡Œå®éªŒ
    results = experiment.run_experiment()

    # ç”Ÿæˆæ±‡æ€»è¡¨æ ¼
    summary = experiment.generate_summary_table()

    # è·³è¿‡å›¾è¡¨ç”Ÿæˆ
    experiment.plot_results()

    # åˆ†ææœ€ä¼˜å‚æ•°
    optimal_mu = experiment.analyze_optimal_mu()

    print(f"\nğŸ¯ å®éªŒå®Œæˆï¼æœ€ä¼˜Î¼å€¼: {optimal_mu}")
    print("è¾“å‡ºæ–‡ä»¶:")
    print("- S_mu_ablation_summary.csv (æ±‡æ€»è¡¨æ ¼)")

if __name__ == "__main__":
    main()
