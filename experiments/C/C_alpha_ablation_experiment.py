"""
C(t) Alphaå‚æ•°æ¶ˆèå®éªŒ

æµ‹è¯•ä¸åŒalphaå€¼å¯¹å±€éƒ¨è¯­ä¹‰èšç±»å¯†åº¦C(t)çš„å½±å“
alphaå€¼èŒƒå›´: 0.2, 0.3, 0.4, 0.5, 0.6

å®éªŒè¾“å‡º:
- ç»Ÿè®¡è¡¨æ ¼
- è¶‹åŠ¿å›¾è¡¨
- è¯¦ç»†åˆ†ææŠ¥å‘Š
"""

import torch
import sys
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
# å½“å‰æ–‡ä»¶: experiments/C/C_alpha_ablation_experiment.py
# é¡¹ç›®æ ¹ç›®å½•: ../../../../
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.append(project_root)
print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")

# ç›´æ¥å¯¼å…¥æ¨¡å—
sys.path.append(os.path.join(project_root, 'SD'))
from llm_hidden_extractor import extract_hidden_states
from c_t_calculator import compute_c_t, compute_c_t_batch
from m_t_calculator import ChineseMorphExtractor, compute_m_t_full

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“ - ä¿®å¤ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 12

# è®¾ç½®seaborné£æ ¼
sns.set_style("whitegrid")
sns.set_palette("husl")

class AlphaAblationExperiment:
    """C(t) Alphaå‚æ•°æ¶ˆèå®éªŒ"""

    def __init__(self):
        self.alpha_values = [0.2, 0.3, 0.4, 0.5, 0.6,0.7,0.8,0.9]
        self.test_sentences = [
             "æ±Ÿæ²³æ¹–æµ·éƒ½æ˜¯æ°´"
        ]
        self.results = defaultdict(dict)

    def run_experiment(self):
        """è¿è¡Œæ¶ˆèå®éªŒ"""
        print("=" * 80)
        print("C(t) Alphaå‚æ•°æ¶ˆèå®éªŒ")
        print("=" * 80)
        print(f"æµ‹è¯•Alphaå€¼: {self.alpha_values}")
        print(f"æµ‹è¯•å¥å­æ•°é‡: {len(self.test_sentences)}")
        print()

        # åˆå§‹åŒ–å½¢æ€ç‰¹å¾æå–å™¨
        morph_extractor = ChineseMorphExtractor()

        for sentence_idx, sentence in enumerate(self.test_sentences):
            print(f"å¤„ç†å¥å­ {sentence_idx + 1}/{len(self.test_sentences)}: {sentence}")
            print("-" * 60)

            # æå–å¥å­ç‰¹å¾
            try:
                hidden_states, token_num, tokenizer, inputs, attentions = extract_hidden_states(
                    text=sentence,
                    middle_layer_idx=12,
                    device="cuda" if torch.cuda.is_available() else "cpu"
                )

                # è§£ç tokens
                tokens = []
                for i in range(len(inputs['input_ids'][0])):
                    token_text = tokenizer.decode([inputs['input_ids'][0][i]])
                    tokens.append(token_text)

                print(f"åˆ†è¯ç»“æœ: {tokens}")
                print(f"Tokenæ•°é‡: {len(tokens)}")

                # å¯¹æ¯ä¸ªalphaå€¼è¿›è¡Œæµ‹è¯•
                for alpha in self.alpha_values:
                    print(f"\næµ‹è¯• Alpha = {alpha}")
                    print("-" * 30)

                    c_t_values = []
                    m_t_values = []

                    # è®¡ç®—æ¯ä¸ªtokençš„C(t)å’ŒM(t)
                    for token_idx, token_text in enumerate(tokens):
                        try:
                            h_t = hidden_states[token_idx]

                            # è®¡ç®—M(t)
                            m_t_value = compute_m_t_full(
                                h_t=h_t,
                                token_text=token_text,
                                tokens=tokens,
                                token_idx=token_idx,
                                hidden_states=hidden_states,
                                layer_idx=12  # ä½¿ç”¨ç¬¬12å±‚ï¼Œä¸LLMç‰¹å¾æå–ä¸€è‡´
                            )

                            # è®¡ç®—C(t)
                            c_t_value = compute_c_t(
                                h_t=h_t,
                                hidden_states=hidden_states,
                                token_idx=token_idx,
                                k=3,
                                theta=0.5,
                                alpha=alpha,
                                precomputed_m_t=m_t_value
                            )

                            c_t_values.append(c_t_value)
                            m_t_values.append(m_t_value)

                            print(f"  '{token_text}': C(t)={c_t_value:.6f}, M(t)={m_t_value:.6f}")

                        except Exception as e:
                            print(f"  é”™è¯¯å¤„ç†token '{token_text}': {e}")
                            c_t_values.append(0.0)
                            m_t_values.append(0.0)

                    # ç»Ÿè®¡ç»“æœ
                    c_t_array = np.array(c_t_values)
                    m_t_array = np.array(m_t_values)

                    stats = {
                        'sentence': sentence,
                        'sentence_idx': sentence_idx,
                        'alpha': alpha,
                        'tokens': tokens,
                        'c_t_values': c_t_values,
                        'm_t_values': m_t_values,
                        'c_t_mean': float(np.mean(c_t_array)),
                        'c_t_std': float(np.std(c_t_array)),
                        'c_t_max': float(np.max(c_t_array)),
                        'c_t_min': float(np.min(c_t_array)),
                        'c_t_range': float(np.max(c_t_array) - np.min(c_t_array)),
                        'm_t_mean': float(np.mean(m_t_array)),
                        'm_t_std': float(np.std(m_t_array)),
                    }

                    self.results[alpha][sentence] = stats

                    print(f"ç»Ÿè®¡ç»“æœ:")
                    print(f"  C(t) - å‡å€¼: {stats['c_t_mean']:.6f}, æ ‡å‡†å·®: {stats['c_t_std']:.6f}")
                    print(f"  C(t) - èŒƒå›´: [{stats['c_t_min']:.6f}, {stats['c_t_max']:.6f}]")
                    print(f"  M(t) - å‡å€¼: {stats['m_t_mean']:.6f}, æ ‡å‡†å·®: {stats['m_t_std']:.6f}")

                print()

            except Exception as e:
                print(f"å¤„ç†å¥å­å¤±è´¥: {e}")
                continue

        print("å®éªŒå®Œæˆï¼")
        return self.results

    def generate_summary_table(self):
        """ç”Ÿæˆæ±‡æ€»è¡¨æ ¼"""
        print("\n" + "=" * 80)
        print("å®éªŒç»“æœæ±‡æ€»è¡¨")
        print("=" * 80)

        # åˆ›å»ºæ±‡æ€»æ•°æ®
        summary_data = []
        for alpha in self.alpha_values:
            alpha_stats = []
            for sentence in self.test_sentences:
                if sentence in self.results[alpha]:
                    stats = self.results[alpha][sentence]
                    alpha_stats.append({
                        'sentence': sentence,
                        'c_t_mean': stats['c_t_mean'],
                        'c_t_std': stats['c_t_std'],
                        'c_t_range': stats['c_t_range'],
                        'm_t_mean': stats['m_t_mean']
                    })

            if alpha_stats:
                # è®¡ç®—alphaçš„æ•´ä½“ç»Ÿè®¡
                c_t_means = [s['c_t_mean'] for s in alpha_stats]
                c_t_stds = [s['c_t_std'] for s in alpha_stats]
                c_t_ranges = [s['c_t_range'] for s in alpha_stats]
                m_t_means = [s['m_t_mean'] for s in alpha_stats]

                summary_data.append({
                    'Alpha': alpha,
                    'C(t)_Mean': f"{np.mean(c_t_means):.6f}",
                    'C(t)_Std': f"{np.mean(c_t_stds):.6f}",
                    'C(t)_Range_Mean': f"{np.mean(c_t_ranges):.6f}",
                    'M(t)_Mean': f"{np.mean(m_t_means):.6f}",
                    'Sentence_Count': len(alpha_stats)
                })

        # æ‰“å°è¡¨æ ¼
        if summary_data:
            df = pd.DataFrame(summary_data)
            print(df.to_string(index=False))

            # ä¿å­˜åˆ°CSV
            df.to_csv('C_alpha_ablation_summary.csv', index=False)
            print(f"\næ±‡æ€»è¡¨å·²ä¿å­˜åˆ°: C_alpha_ablation_summary.csv")

        return summary_data

    def plot_results(self):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        print("\n" + "=" * 80)
        print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
        print("=" * 80)

        # 1. Alpha vs C(t)å‡å€¼è¶‹åŠ¿å›¾
        plt.figure(figsize=(12, 8))

        alphas = []
        c_t_means = []
        c_t_stds = []

        for alpha in self.alpha_values:
            alpha_c_t_means = []
            for sentence in self.test_sentences:
                if sentence in self.results[alpha]:
                    alpha_c_t_means.append(self.results[alpha][sentence]['c_t_mean'])

            if alpha_c_t_means:
                alphas.append(alpha)
                c_t_means.append(np.mean(alpha_c_t_means))
                c_t_stds.append(np.std(alpha_c_t_means))

        plt.subplot(2, 2, 1)
        plt.errorbar(alphas, c_t_means, yerr=c_t_stds, fmt='o-', capsize=5, linewidth=2, markersize=8)
        plt.xlabel('Alpha å€¼')
        plt.ylabel('C(t) å‡å€¼')
        plt.title('Alpha vs C(t)å‡å€¼è¶‹åŠ¿')
        plt.grid(True, alpha=0.3)

        # 2. Alpha vs C(t)èŒƒå›´è¶‹åŠ¿å›¾
        alphas = []
        c_t_ranges = []

        for alpha in self.alpha_values:
            alpha_c_t_ranges = []
            for sentence in self.test_sentences:
                if sentence in self.results[alpha]:
                    alpha_c_t_ranges.append(self.results[alpha][sentence]['c_t_range'])

            if alpha_c_t_ranges:
                alphas.append(alpha)
                c_t_ranges.append(np.mean(alpha_c_t_ranges))

        plt.subplot(2, 2, 2)
        plt.plot(alphas, c_t_ranges, 's-', linewidth=2, markersize=8, color='orange')
        plt.xlabel('Alpha å€¼')
        plt.ylabel('C(t) èŒƒå›´å‡å€¼')
        plt.title('Alpha vs C(t)åŒºåˆ†åº¦')
        plt.grid(True, alpha=0.3)

        # 3. ä¸åŒå¥å­åœ¨ä¸åŒAlphaä¸‹çš„C(t)åˆ†å¸ƒ
        plt.subplot(2, 2, 3)
        sentence_names = [f"å¥å­{i+1}" for i in range(len(self.test_sentences))]

        for i, sentence in enumerate(self.test_sentences):
            alpha_means = []
            for alpha in self.alpha_values:
                if sentence in self.results[alpha]:
                    alpha_means.append(self.results[alpha][sentence]['c_t_mean'])
                else:
                    alpha_means.append(0)

            plt.plot(self.alpha_values, alpha_means, 'o-', label=sentence_names[i],
                    linewidth=2, markersize=6)

        plt.xlabel('Alpha å€¼')
        plt.ylabel('C(t) å‡å€¼')
        plt.title('å„å¥å­åœ¨ä¸åŒAlphaä¸‹çš„C(t)å˜åŒ–')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.grid(True, alpha=0.3)

        # 4. Alphaå‚æ•°æ•æ„Ÿæ€§åˆ†æ
        plt.subplot(2, 2, 4)

        # è®¡ç®—æ¯ä¸ªalphaçš„å˜å¼‚ç³»æ•° (std/mean)
        alphas = []
        cv_values = []  # å˜å¼‚ç³»æ•°

        for alpha in self.alpha_values:
            alpha_c_t_values = []
            for sentence in self.test_sentences:
                if sentence in self.results[alpha]:
                    alpha_c_t_values.extend(self.results[alpha][sentence]['c_t_values'])

            if alpha_c_t_values:
                alphas.append(alpha)
                mean_val = np.mean(alpha_c_t_values)
                std_val = np.std(alpha_c_t_values)
                cv = std_val / mean_val if mean_val > 0 else 0
                cv_values.append(cv)

        plt.bar(alphas, cv_values, alpha=0.7, color='green')
        plt.xlabel('Alpha å€¼')
        plt.ylabel('å˜å¼‚ç³»æ•° (Std/Mean)')
        plt.title('Alphaå‚æ•°æ•æ„Ÿæ€§åˆ†æ')
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig('C_alpha_ablation_plots.png', dpi=300, bbox_inches='tight')
        print("å›¾è¡¨å·²ä¿å­˜åˆ°: C_alpha_ablation_plots.png")

        # æ˜¾ç¤ºå›¾è¡¨
        plt.show()

    def analyze_optimal_alpha(self):
        """åˆ†ææœ€ä¼˜Alphaå€¼"""
        print("\n" + "=" * 80)
        print("æœ€ä¼˜Alphaå€¼åˆ†æ")
        print("=" * 80)

        # é‡æ–°è®¾è®¡è¯„åˆ†æœºåˆ¶ï¼šè€ƒè™‘å½¢æ€æ ¡æ­£çš„åˆç†æ€§å’Œå¹³è¡¡æ€§
        alpha_scores = {}

        for alpha in self.alpha_values:
            scores = []

            for sentence in self.test_sentences:
                if sentence in self.results[alpha]:
                    stats = self.results[alpha][sentence]

                    # è®¡ç®—åŸºç¡€å¯†åº¦ï¼ˆå½“alpha=0æ—¶çš„C(t)å‡å€¼ï¼Œä½œä¸ºåŸºå‡†ï¼‰
                    base_c_t_mean = None
                    if 0.2 in self.results and sentence in self.results[0.2]:
                        # ä½¿ç”¨æœ€å°alphaå€¼ä½œä¸ºåŸºå‡†ï¼ˆå½¢æ€æ ¡æ­£æœ€å°ï¼‰
                        base_stats = self.results[0.2][sentence]
                        base_c_t_mean = base_stats['c_t_mean']

                    if base_c_t_mean is None:
                        # å¦‚æœæ²¡æœ‰åŸºå‡†ï¼Œä½¿ç”¨å½“å‰å€¼çš„80%ä½œä¸ºä¿å®ˆä¼°è®¡
                        base_c_t_mean = stats['c_t_mean'] * 0.8

                    # 1. å½¢æ€æ ¡æ­£å¢ç›Šï¼šç›¸å¯¹äºåŸºç¡€å¯†åº¦çš„æå‡ï¼ˆæƒé‡0.3ï¼‰
                    # ä¸åº”è¯¥è¿‡åº¦æ”¾å¤§ï¼Œä½†è¦æœ‰åˆç†æå‡
                    correction_gain = (stats['c_t_mean'] - base_c_t_mean) / (base_c_t_mean + 1e-8)
                    gain_score = min(correction_gain, 0.5)  # é™åˆ¶æœ€å¤§å¢ç›Šï¼Œé¿å…è¿‡åº¦æ”¾å¤§

                    # 2. æ•°å€¼åˆç†æ€§ï¼šC(t)å€¼åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆæƒé‡0.3ï¼‰
                    # ç†æƒ³èŒƒå›´ï¼š[0.1, 1.0]ï¼Œè¿‡å¤§æˆ–è¿‡å°éƒ½ä¸å¥½
                    mean_reasonable = 1.0 - abs(stats['c_t_mean'] - 0.5) / 0.5  # 0.5ä¸ºä¸­å¿ƒ
                    range_reasonable = min(stats['c_t_range'], 2.0) / 2.0  # èŒƒå›´ä¸åº”è¯¥è¿‡å¤§
                    reasonable_score = (mean_reasonable + range_reasonable) / 2.0

                    # 3. ç¨³å®šæ€§ï¼šæ ‡å‡†å·®ä¸åº”è¯¥è¿‡å¤§ï¼ˆæƒé‡0.2ï¼‰
                    stability_score = 1.0 / (1.0 + stats['c_t_std'])

                    # 4. Alphaåˆç†æ€§æƒ©ç½šï¼šè¿‡å¤§çš„Alphaåº”è¯¥è¢«æƒ©ç½šï¼ˆæƒé‡0.2ï¼‰
                    # Alphaåœ¨[0.2, 0.6]èŒƒå›´å†…ï¼Œ0.4å·¦å³å¯èƒ½æ˜¯æœ€åˆç†çš„
                    alpha_penalty = 1.0 - abs(alpha - 0.4) / 0.4  # 0.4ä¸ºä¸­å¿ƒ
                    alpha_penalty = max(alpha_penalty, 0.1)  # æœ€å°æƒ©ç½š

                    # ç»¼åˆè¯„åˆ†
                    score = (gain_score * 0.3 +
                           reasonable_score * 0.3 +
                           stability_score * 0.2 +
                           alpha_penalty * 0.2)

                    scores.append(score)

            if scores:
                alpha_scores[alpha] = np.mean(scores)

        # æ’åºå¹¶è¾“å‡º
        sorted_alphas = sorted(alpha_scores.items(), key=lambda x: x[1], reverse=True)

        print("Alphaå€¼ç»¼åˆè¯„åˆ† (è€ƒè™‘å¹³è¡¡æ€§å’Œåˆç†æ€§):")
        print("-" * 50)
        for alpha, score in sorted_alphas:
            print(".2f")

        optimal_alpha = sorted_alphas[0][0]
        print(f"\næ¨èæœ€ä¼˜Alphaå€¼: {optimal_alpha}")
        print("é€‰æ‹©ç†ç”±:")
        print(f"- ç»¼åˆè¯„åˆ†æœ€é«˜ ({alpha_scores[optimal_alpha]:.4f})")
        print("- åœ¨å½¢æ€æ ¡æ­£å¢ç›Šã€æ•°å€¼åˆç†æ€§å’Œç¨³å®šæ€§é—´å–å¾—æœ€ä½³å¹³è¡¡")
        print("- é¿å…è¿‡åº¦æ”¾å¤§å½¢æ€æ ¡æ­£å¯¼è‡´çš„ä¸åˆç†èšç±»å¯†åº¦")

        return optimal_alpha

def main():
    """ä¸»å‡½æ•°"""
    experiment = AlphaAblationExperiment()

    # è¿è¡Œå®éªŒ
    results = experiment.run_experiment()

    # ç”Ÿæˆæ±‡æ€»è¡¨æ ¼
    summary = experiment.generate_summary_table()

    # ç”Ÿæˆå›¾è¡¨
    experiment.plot_results()

    # åˆ†ææœ€ä¼˜å‚æ•°
    optimal_alpha = experiment.analyze_optimal_alpha()

    print(f"\nğŸ¯ å®éªŒå®Œæˆï¼æœ€ä¼˜Alphaå€¼: {optimal_alpha}")
    print("è¾“å‡ºæ–‡ä»¶:")
    print("- C_alpha_ablation_summary.csv (æ±‡æ€»è¡¨æ ¼)")
    print("- C_alpha_ablation_plots.png (å¯è§†åŒ–å›¾è¡¨)")

if __name__ == "__main__":
    main()